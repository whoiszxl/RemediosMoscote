# 二.分布式日志收集框架Flume

## 1.业务分析
web/app日志分散在各个机器上,想要将日志传输到Hadoop平台进行统计分析,因为普通的CP方式过于消耗磁盘和网络IO,就需要有个良好的解决方案.

## 2.Flume概述
### 官网概念
Flume is a distributed,reliable,and available service for efficiently collecting,aggregating,and moving large amounts of log data.

### 设计目标
    1.可靠性
    2.扩展性
    3.管理性

### Flume架构和核心组件
1.Source 收集

2.Channel 聚集

3.Sink 输出

### 安装前置条件
    1.Java Runtime Environment - Java 1.8 or later
    2.Memory - Sufficient memory for configurations used by sources, channels or sinks
    3.Disk Space - Sufficient disk space for configurations used by channels or sinks
    4.Directory Permissions - Read/Write permissions for directories used by agent

### 环境搭建
1.JDK配置,解压配置环境变量 and `source ~/.bashrc`
```shell
export JAVA_HOME=/home/hadoop/app/jdk1.8.0_151
export PATH=$JAVA_HOME/bin:$PATH
```

2.tar -zvxf flume-ng-1.6.0-cdh5.7.0.tar.gz解压包

3.配置环境变量 and `source ~/.bashrc`
```shell
export FLUME_HOME=/home/hadoop/app/apache-flume-1.6.0-cdh5.7.0-bin
export PATH=$FLUME_HOME/bin:$PATH
```

4.配置flume目录下的conf/flume-env.sh,配置jdk目录
```shell
export JAVA_HOME=/home/hadoop/app/jdk1.8.0_151
```

5.检测是否安装成功,进入bin目录,执行 `flume-ng version`


## 3.实际案例
使用flume的关键就是写配置文件

### 一个简单的示例(从指定网络端口采集数据输出到控制台)
1.编写配置文件
```xml
# example.conf: A single-node Flume configuration
# 一个单节点的flume配置

# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
# 配置source收集的类型,地址和端口
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 44444

# Describe the sink
# 配置sink输出的方式是打logger方式
a1.sinks.k1.type = logger

# Use a channel which buffers events in memory
# 配置channel聚合的方式是通过内存
a1.channels.c1.type = memory
#a1.channels.c1.capacity = 1000
#a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
# 绑定收集和输出到channel的聚集上面
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

2.启动agent
```shell
 bin/flume-ng agent --name a1 --conf $FLUME_HOME/conf --conf-file $FLUME_HOME/conf/example.conf -Dflume.root.logger=INFO,console
```

3.测试

新开一个终端,通过telnet localhost 44444,然后可以发送消息过去

4.消息分析
```data
Event: { headers:{} body: 77 61 6E 67 6A 69 65 0D                         hello. }
```
Event是flumes数据传输的基本单元
Event = 可选的header + byte array

### 简单的示例(监控一个文件实时采集数据输出到控制台)
Agent选型:exec source + memory channel + logger sink
```properties
# example.conf: A single-node Flume configuration
# 一个单节点的flume配置

# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
# 配置source收集的类型,地址和端口
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /home/hadoop/data/data.log
a1.sources.r1.shell = /bin/sh -c

# Describe the sink
# 配置sink输出的方式是打logger方式
a1.sinks.k1.type = logger

# Use a channel which buffers events in memory
# 配置channel聚合的方式是通过内存
a1.channels.c1.type = memory
#a1.channels.c1.capacity = 1000
#a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
# 绑定收集和输出到channel的聚集上面
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```
启动agent
```shell
 bin/flume-ng agent --name a1 --conf $FLUME_HOME/conf --conf-file $FLUME_HOME/conf/exec-memory-logger.conf -Dflume.root.logger=INFO,console
```

### 重点示例(一个服务器的日志发送到另外一个服务器)

技术选型:
    
    Server1:exec source + memory channel + avro sink
    Server2:avro source + memory channel + logger sink

配置文件: `exec-memory-avro.conf`
```properties
exec-memory-avro.sources = exec-source
exec-memory-avro.sinks = avro-sink
exec-memory-avro.channels = memory-channel

exec-memory-avro.sources.exec-source.type = exec
exec-memory-avro.sources.exec-source.command = tail -F /home/hadoop/data/data.log
exec-memory-avro.sources.exec-source.shell = /bin/sh -c

exec-memory-avro.sinks.avro-sink.type = avro
exec-memory-avro.sinks.avro-sink.hostname = localhost
exec-memory-avro.sinks.avro-sink.port = 44444

exec-memory-avro.channels.memory-channel.type = memory

exec-memory-avro.sources.exec-source.channels = memory-channel
exec-memory-avro.sinks.avro-sink.channel = memory-channel
```


配置文件: `avro-memory-logger.conf`
```properties
avro-memory-logger.sources = avro-source
avro-memory-logger.sinks = logger-sink
avro-memory-logger.channels = memory-channel

avro-memory-logger.sources.avro-source.type = avro
avro-memory-logger.sources.avro-source.bind = localhost
avro-memory-logger.sources.avro-source.port = 44444

avro-memory-logger.sinks.logger-sink.type = logger

avro-memory-logger.channels.memory-channel.type = memory

avro-memory-logger.sources.avro-source.channels = memory-channel
avro-memory-logger.sinks.logger-sink.channel = memory-channel
```

启动agent
```shell
 bin/flume-ng agent --name exec-memory-avro --conf $FLUME_HOME/conf --conf-file $FLUME_HOME/conf/exec-memory-avro.conf -Dflume.root.logger=INFO,console

 bin/flume-ng agent --name avro-memory-logger --conf $FLUME_HOME/conf --conf-file $FLUME_HOME/conf/avro-memory-logger.conf -Dflume.root.logger=INFO,console
```